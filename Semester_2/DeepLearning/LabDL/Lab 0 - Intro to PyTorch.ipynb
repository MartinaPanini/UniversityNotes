{"cells":[{"cell_type":"markdown","metadata":{"id":"Xm7rf7fIv3Rg"},"source":["# Deep Learning Lab #0 - Introduction to PyTorch\n","Welcome to the first laboratory session of the Deep Learning course. Today, we will examine PyTorch, a Python library for **Deep Learning**. PyTorch allows us to build and train deep models in an efficient and intuitive way, leaving most of the mechanics to be carried out **automatically**, such as:\n","* GPU support\n","* Automatic gradient computation for back-propagation\n","\n","### On today's menu:\n","We are going to take a look at the main functionalities of PyTorch, such as:\n","* tensor operations;\n","* computational graph and backpropagation;\n","* modules;\n","* loss functions;\n","* optimizers;\n","* datasets and dataloaders."]},{"cell_type":"markdown","metadata":{"id":"TU9gGYgZXkWZ"},"source":["To install PyTorch, follow the instructions at https://pytorch.org/get-started/locally/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i4JG4w_8XkWZ"},"outputs":[],"source":["!pip3 install torch torchvision torchaudio matplotlib wandb tensorboard -q"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PChhCL3eXkWa"},"outputs":[],"source":["# Let's start by importing the library\n","import torch"]},{"cell_type":"markdown","metadata":{"id":"j7lwpSH134L7"},"source":["## Tensor operations\n","PyTorch provides a specific class called **Tensor**, that encodes scalar values as well as multidimensional vectors.\n","PyTorch offers a wide variety of methods for creating and manipulating tensors, with most NumPy functions being directly supported. Let us start with an overview of some methods for tensor creation."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"39r0DLYo3evx"},"outputs":[],"source":["# Create a (2, 3) tensor from python data\n","data = [\n","    [1.0, 2.0, 3.0],\n","    [4.0, 5.0, 6.0]\n","]\n","a = torch.tensor(data)\n","print(\"> Tensor from python data\")\n","print(a)\n","\n","# Creates a (2, 3) tensor with all 0s\n","b = torch.zeros((2, 3))\n","print(\"> Tensor with all 0s\")\n","print(b)\n","\n","# Creates a (2, 3) tensor with all 1s\n","c = torch.ones((2, 3))\n","print(\"> Tensor with all 1s\")\n","print(c)\n","\n","# Creates a (1, 4, 3) tensor with values from a normal distribution\n","d = torch.randn((1, 4, 3))\n","print(\"> Tensor with random values\")\n","print(d)\n","\n","# Creates a tensor with values from 1 to 10\n","e = torch.arange(1, 10)\n","print(\"> Tensor with values from 1 to 10\")\n","print(e)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hcPoLI-YXkWb"},"outputs":[],"source":["# Unless specified, the default type for tensors is float32\n","# For a list fo all tensor types => https://pytorch.org/docs/stable/tensor_attributes.html\n","print(f\"torch.get_default_dtype() = {torch.get_default_dtype()}\")\n","\n","# We can change the tensor type in two ways:\n","# (a) directly when creating the tensor\n","f = torch.zeros((2, 3), dtype=torch.int32)\n","print(\"> Tensor with all 0s as int32\")\n","print(f)\n","\n","# (b) after tensor creation\n","f = torch.zeros((2, 3)).int()\n","print(\"> Tensor with all 0s cast to int32\")\n","print(f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eonA4AT5XkWb"},"outputs":[],"source":["# NOTE: some operators are not implemented for some types, e.g.\n","# this_will_crash = torch.randn((1, 4, 3), dtype=torch.int32)\n","\n","# In these cases, we can only cast later\n","this_wont_crash = torch.randn((1, 4, 3)).long()\n","print(this_wont_crash)"]},{"cell_type":"markdown","metadata":{"id":"uHOR27X94RVm"},"source":["PyTorch supports the basic python operators, which are applied elementwise to the tensors."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7KTg7PCz4H8H"},"outputs":[],"source":["# Create a (2, 3) tensor from python data\n","a = torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n","print(\"> a\")\n","print(a)\n","\n","# Create a (2, 3) tensor with all 1s\n","b = torch.ones((2, 3))\n","print(\"> b\")\n","print(b)\n","\n","a = a * 2\n","print(\"> a * 2\")\n","print(a)\n","\n","print(\"> (a * 2) + b\")\n","a = a + b\n","print(a)\n","\n","print(\"> ((a * 2) + b)^2\")\n","a = a ** 2\n","print(a)"]},{"cell_type":"markdown","metadata":{"id":"DpC9RtAM4bl2"},"source":["Other operations, instead, operate on entire dimensions of the tensors and can change their size."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4EXn5F_14WFD"},"outputs":[],"source":["# Create a (2, 3) tensor from python data\n","a = torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n","print(\"> a\")\n","print(a)\n","\n","# To find the shape of the tensor, we can use the .shape of tensors\n","print(\"> a.shape\")\n","print(a.shape)\n","\n","# Sum the values along the dimensions of the rows\n","b = torch.sum(a, dim=0)\n","print(\"> torch.sum(a, dim=0)\")\n","print(b)\n","print(b.shape)\n","\n","# Sum the values in a along the dimensions of the columns\n","c = torch.sum(a, dim=1)\n","print(\"> torch.sum(a, dim=1)\")\n","print(c)\n","print(c.shape)\n","\n","# Sum all values in a\n","d = torch.sum(a)\n","print(\"> torch.sum(a)\")\n","print(d)\n","print(d.shape)"]},{"cell_type":"markdown","metadata":{"id":"b8RTZ5K-403k"},"source":["Tensor indexing in PyTorch is quite similar to NumPy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NY7olAuZ4leX"},"outputs":[],"source":["# Create a (2, 3) tensor from python data\n","a = torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n","print(\"> a\")\n","print(a)\n","\n","# Index a specific scalar\n","print(\"> a[0, 0]\")\n","print(a[0, 0])\n","\n","# Index row 0\n","print(\"> a[0]\")\n","print(a[0])\n","\n","# Index column 0\n","print(\"> a[:, 0]\")\n","print(a[:, 0])\n","\n","# Index columns 0 and 1\n","print(\"> a[:, 0:2]\")\n","print(a[:, 0:2])\n","\n","# Index the elements greater or equal to 3.0\n","print(\"> a[a >= 3.0]\")\n","print(a[a >= 3.0])\n","\n","# The returned tensors share the memory with the original tensor\n","a[a >= 3.0] += 10\n","print(\"> a[a >= 3.0] += 10\")\n","print(a)\n","\n","# To clone a tensor, you can use the .clone function\n","b = a.clone()\n","b[b >= 3.0] -= 10\n","print(\"> b[b >= 3.0] -= 10\")\n","print(b)"]},{"cell_type":"markdown","metadata":{"id":"_qdbcqDr5Flc"},"source":["PyTorch supports a concept called **Tensor Broadcasting**, which is designed to automatically deal with operations involving tensors of **different sizes**. This often happens in practice, as in the case where an entire tensor is multiplied by a single scalar.\n","\n","Given two tensors, we say that they are \"broadcastable\" if, when iterating over their dimensions starting from the last one and proceeding towards the initial ones, one of these conditions hold for the size of the dimensions:\n","\n","1. **they match**: no special treatment is needed in this case\n","2. **one of them is 1**: the dimension of size 1 is replicated to make it reach the size of the corresponding dimension in the other tensor\n","3. **one of them does not exist**: the dimension is created with size 1 and the former rule applies\n","\n","Let's see some examples"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"33bF8Kqo5DH2"},"outputs":[],"source":["# Create a (2, 3) tensor\n","a = torch.arange(1, 7).reshape(2, 3)\n","print(\"> a\")\n","print(a)\n","print(a.shape)\n","\n","# Create a scalar value with no dimensions\n","b = torch.ones(())\n","print(\"> b\")\n","print(b)\n","print(b.shape)\n","\n","# We want to sum a and b. Which Tensor Broadcasting rules are we using?\n","c = a + b\n","\n","print(\"> c = a + b\")\n","print(c)\n","print(c.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s2KXRG5x5nwA"},"outputs":[],"source":["# Create a (2, 1, 3) tensor\n","a = torch.ones((2, 1, 3))\n","print(\"> a\")\n","print(a)\n","print(a.shape)\n","\n","# Create a (4, 1) tensor\n","b = torch.randn((4, 1))\n","print(b)\n","print(b.shape)\n","\n","# Will this work?\n","c = a + b\n","\n","print(\"> c = a + b\")\n","print(c)\n","print(c.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nJME9ix9XkWd"},"outputs":[],"source":["# Create a (2, 1, 3) tensor\n","a = torch.ones((2, 1, 3))\n","print(\"> a\")\n","print(a)\n","print(a.shape)\n","\n","# Create a (1, 4) tensor\n","b = torch.randn((1, 4))\n","print(\"> b\")\n","print(b)\n","print(b.shape)\n","\n","# Will this work?\n","c = a + b\n","\n","print(\"> c = a + b\")\n","print(c)\n","print(c.shape)"]},{"cell_type":"markdown","metadata":{"id":"kxjwf53Y553P"},"source":["The `squeeze()` and `unsqueeze()` methods are often used in conjunction with broadcasting. These methods respectively remove or add a dimension with size 1 in the tensor on which they are called."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u99kJt2T6BT9"},"outputs":[],"source":["# Create a (2) tensor\n","a = torch.arange(0, 2)\n","print(\"> a\")\n","print(a)\n","print(a.shape)\n","\n","# Create a (3) tensor\n","b = torch.arange(0, 3)\n","print(\"> b\")\n","print(b)\n","print(b.shape)\n","\n","# Say we want to multiply each element in a with each element in b, getting a (2, 3) tensor.\n","# With the current tensor shapes, broadcasting won't work\n","# c = a * b\n","\n","# To leverage broadcast, we can add a trailing 1 dimension to a and multiply\n","print(\"> a.unsqueeze(dim=-1)\")\n","a = a.unsqueeze(dim=-1)\n","print(a)\n","print(a.shape)\n","\n","c = a * b\n","print(\"> c = a * b\")\n","print(c)\n","print(c.shape)"]},{"cell_type":"markdown","metadata":{"id":"8Ct7XJEy54Hp"},"source":["PyTorch adopts some conventions on the shape of the tensors expected by its modules. 1D data is typically represented in the `(batch_size, features_count)` format. 2D data instead is represented in the `(batch_size, channels, height, width)` format."]},{"cell_type":"markdown","metadata":{"id":"OwjUJauex17d"},"source":["## Tensors and Computational Graphs\n","To compute the gradients of a given function for the optimization process, we need to track its input and the operations applied to it. This tracking results in an object called a Computational Graph.\n","\n","<img src=\"https://colah.github.io/posts/2015-08-Backprop/img/tree-eval-derivs.png\" width=\"500\"></br></br>\n","\n","For each operation executed, a new node is appended to the graph, allowing us to exploit the **chain rule** to compute all the derivatives in a single back-propagation pass. To efficiently support this functionality, PyTorch provides gradient support for each Tensor."]},{"cell_type":"markdown","metadata":{"id":"VewavC510wJ4"},"source":["Let us now create two tensors containing scalar value and define some operations on them"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HXJwkefv0rRw"},"outputs":[],"source":["# Create the tensors. By default tensors do not require gradients, so we enable them\n","a = torch.tensor([2.0], requires_grad=True)\n","b = torch.tensor([3.0], requires_grad=True)\n","\n","print(\"> a\")\n","print(a)\n","print(\"> b\")\n","print(b)\n","\n","# The result c is also a tensor\n","c = a * b\n","print(\"> c = a * b\")\n","print(c)"]},{"cell_type":"markdown","metadata":{"id":"zOtfzxLS09Pe"},"source":["All the intermediate values of the computation performed in the background by the machine are tracked in order to enable back-propagation. Our computational graph will have a node for `a`, one for `b` and one for the `*` operation. Let us now compute the gradients of `c = a * b` with respect to one of its inputs."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xfQo2i3R03IY"},"outputs":[],"source":["print(\"Gradient before computation\")\n","print(a.grad)\n","print(b.grad)\n","c.backward()\n","print(\"Gradient after computation\")\n","print(a.grad)\n","print(b.grad)"]},{"cell_type":"markdown","metadata":{"id":"aSiIKj7Q1gP_"},"source":["Calling the `backward()` method deallocates the computational graph, releasing the memory used to store it, and updates the `grad` attribute of each tensor, summing to it the newly computed gradient. It's easy to see how this automatic differentiation save lots of coding. Take as an example the code that would be needed to manually implement gradient computation in Numpy for a linear layer:\n","\n","\n","```python\n","# define derivative of the activation\n","def derivative_sigmoid(z):\n","  return sigmoid(z) * (1 - sigmoid(z))\n","\n","# =========== BACKWARD =========== #\n","\n","# compute gradient from L to z\n","dL_dy = -2 * (t - y)\n","dL_dz = dL_dy * derivative_sigmoid(z)\n","\n","# compute gradient w.r.t. input\n","dL_dx = np.dot(dL_dz, W)\n","\n","# compute gradient w.r.t. parameters\n","dL_dW = np.dot(x, dL_dz)\n","dL_db = dl_dZ\n","```"]},{"cell_type":"markdown","metadata":{"id":"3KRUufwa27wv"},"source":["## Working with different devices\n","Until now, our operations were executed on **CPU**. PyTorch, however, supports a wide range of processors for execution, including **GPUs** and **TPUs**. These are called **Devices**. Using the correct device can have a huge impact on **performance**. In order to execute an operation on a specific device, we first need to move all the involved tensors to the memory of such a device. The operation will then be automatically executed on that device."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7wyxb4Tb1b2f"},"outputs":[],"source":["# Check if we have CUDA support\n","print(\"> torch.cuda.is_available()\")\n","print(torch.cuda.is_available())\n","\n","# Fetch the first GPU. In the case of multiple GPUs, the index specifies which GPU to use\n","device = \"cuda:0\"\n","\n","# Create some tensors in GPU memory\n","a = torch.tensor([2.0], device=device)\n","# Create tensor in CPU and move it to GPU\n","b = torch.tensor([3.0]).to(device)\n","\n","# The result c is also on the GPU\n","c = a * b\n","\n","print(\"> c.device\")\n","print(c.device)"]},{"cell_type":"markdown","metadata":{"id":"gazgcLlA3rdj"},"source":["Different operations can also be executed on different devices. PyTorch will automatically keep track of it in the Computational Graph. We now have all the ingredients we need to create and train a deep model. However, using operations at such a low level is unconvenient and prone to errors. We will now look at additional functionalities offered by the library to speed up development."]},{"cell_type":"markdown","metadata":{"id":"24uz0xAc6aFt"},"source":["## Modules\n","Let use what we learned so far to implement a simple linear layer:\n","`y = Wx + b`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ib9xTTwF6WxQ"},"outputs":[],"source":["def apply_linear_layer(x, W, b):\n","    \"\"\"Apply a linear layer on an input.\n","\n","    Args:\n","    x (batch_size, in_features)\n","    W (out_features, in_features)\n","    b (out_features)\n","    \"\"\"\n","\n","    # (1, out_features, in_features)\n","    W = W.unsqueeze(0)\n","    # (batch_size, in_features, 1)\n","    x = x.unsqueeze(-1)\n","\n","    # (batch_size, out_features, 1)\n","    product = torch.matmul(W, x).squeeze(-1)\n","\n","    # (batch_size, out_features)\n","    result = product + b\n","    return result\n","\n","batch_size = 4\n","in_features = 8\n","out_features = 16\n","\n","# Create input\n","x = torch.randn((batch_size, in_features))\n","\n","# Weights of the linear layer\n","W = torch.randn((out_features, in_features), requires_grad=True)\n","b = torch.zeros((out_features), requires_grad=True)\n","\n","# Get output\n","output = apply_linear_layer(x, W, b)\n","\n","print(\"> output\")\n","print(output)\n","print(output.shape)"]},{"cell_type":"markdown","metadata":{"id":"aplxYH736pq_"},"source":["While the layer is functional, instantiating multiple such layers quickly becomes **unmanageable**. The main problem lies in the fact that the weights of the layer **are not tied** with the computational logic: creating a **class** for the layer would solve this problem. PyTorch provides a base class (`torch.nn.Module`) for such purpose, providing various functionalities.\n","\n","Let's implement our linear layer in PyTorch style."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NCF_d5SI6l1z"},"outputs":[],"source":["import torch\n","from torch import nn\n","\n","class MyLinear(nn.Module):\n","    def __init__(self, in_features, out_features):\n","        \"\"\"Linear layer.\n","\n","        Args:\n","          in_features: number of input features\n","          out_features: number of output features\n","        \"\"\"\n","        super(MyLinear, self).__init__()\n","\n","        # Creates tensors for the weights\n","        W = torch.randn((out_features, in_features))\n","        b = torch.zeros((out_features))\n","\n","        # Uses the Parameter class (subclass of Tensor) to create parameters for the module\n","        # When assigned to a member of self, Parameter tensors are automatically registered\n","        # Require gradient by default\n","        # Other Module objects are also automatically registered if assigned to self\n","        self.W = nn.Parameter(W)\n","        self.b = nn.Parameter(b)\n","\n","    def forward(self, x):\n","        \"\"\"Method executed when the object is called.\n","\n","        Args:\n","          x (batch_size, in_features)\n","\n","        Return:\n","          tensors (batch_size, out_features)\n","        \"\"\"\n","\n","        # (batch_size, in_features, 1)\n","        x = x.unsqueeze(-1)\n","        # Note that Parameters\n","        # (1, out_features, in_features)\n","        W = self.W.unsqueeze(0)\n","\n","        # (batch_size, out_features, 1)\n","        product = torch.matmul(W, x).squeeze(-1)\n","\n","        # (batch_size, out_features)\n","        result = product + self.b\n","        return result\n","\n","batch_size = 4\n","in_features = 8\n","out_features = 16\n","\n","x = torch.randn((batch_size, in_features))\n","\n","# Creates an instance of our linear layer\n","linear_layer = MyLinear(in_features, out_features)\n","# Computes the results. the forward method is internally called\n","output = linear_layer(x)\n","\n","print(\"> output\")\n","print(output)\n","print(output.shape)"]},{"cell_type":"markdown","metadata":{"id":"Brgzsx9t7K7R"},"source":["Note how now both the parameters, their initialization and the processing logic are contained in the class. Multiple instances can be handled more conveniently. The Module class provides a range of additional functionalities."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tel5GSH_7CyC"},"outputs":[],"source":["# Obtain all the parameters in the model. Useful for model optimization\n","for name, values in linear_layer.named_parameters():\n","    print(name, values)\n","\n","# Move all the tensors associated to the model to the specified device\n","# recursively applies to other Module objects contained in the instance\n","linear_layer.to(\"cuda:0\")\n","\n","# Saving the model weights\n","print(\"> Saving model\")\n","saved_model = linear_layer.state_dict()\n","torch.save(saved_model, \"save.pth\")\n","\n","# Load the saved model\n","print(\"> Loading model\")\n","loaded_state_dict = torch.load(\"save.pth\")\n","linear_layer.load_state_dict(loaded_state_dict)"]},{"cell_type":"markdown","metadata":{"id":"6lxffBzC7atH"},"source":["PyTorch provides a wide range of `Module` implementations representing the most common computational blocks. These include\n","\n","*   Linear layers\n","*   1D, 2D and 3D Convolutions\n","*   Transposed Convolutions\n","*   Batch/Layer Normalization layers\n","*   RNN, LSTM, GRU cells\n","*   Multi-head Attention Layers\n","* ...\n","\n","Moreover, many common networks are implemented as `Module`s\n","*   Alexnet\n","*   VGG\n","*   ResNet\n","*   DenseNet\n","*   Transformers\n","*   Vision Transformers\n","*   ..."]},{"cell_type":"markdown","metadata":{"id":"HUG64uMf7kFP"},"source":["## Loss functions\n","PyTorch provides a wide range of already implemented loss functions as part of `torch.nn`, such as:\n","*   L1\n","*   MSE\n","*   Cross Entropy\n","*   Binary Cross Entropy\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2LpznBdQ7UoC"},"outputs":[],"source":["import torch\n","from torch import nn\n","\n","# Create some tensors for the loss\n","a = torch.zeros((2, 4))\n","b = torch.ones((2, 4)) * 2\n","\n","# Instantiate the loss\n","l1_loss = nn.L1Loss()\n","mse_loss = nn.MSELoss()\n","\n","# Compute the loss functions\n","loss = l1_loss(a, b)\n","print(\"> l1_loss(a, b)\")\n","print(loss)\n","\n","loss = mse_loss(a, b)\n","print(\"> mse_loss(a, b)\")\n","print(loss)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P4bWW68OXkWh"},"outputs":[],"source":["# Loss functions are also able to perform back-propagation of gradients\n","a = torch.rand((2, 4), requires_grad=True)\n","b = torch.rand((2, 4), requires_grad=True)\n","\n","loss = l1_loss(a, b)\n","print(\"> l1_loss(a, b)\")\n","print(loss)\n","\n","print(\"> Before backward\")\n","print(a.grad)\n","print(b.grad)\n","\n","loss.backward()\n","\n","print(\"> After backward\")\n","print(a.grad)\n","print(b.grad)"]},{"cell_type":"markdown","metadata":{"id":"tPF6ODoM8agv"},"source":["## Optimizers\n","\n","PyTorch implements a wide range of optimizers as part of the `torch.optim` package. When an optimizer is created, a sequence of tensors to optimize is required. The optimizer then uses each tensor's `grad` attribute to update its value.\n","\n","A typical optimization cycle is made of the following steps:\n","\n","1.   perform the computations that build the Computational Graph;\n","2.   compute the loss term;\n","3.   use `backward()` to compute gradients for each tensor in the Computational Graph;\n","4.   perform an optimization step using the optimizer;\n","5.   zero the gradient in all tensors for the next optimization cycle using `zero_grad()`;"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1CJ-vZIa8XSs"},"outputs":[],"source":["import torch\n","from torch import nn\n","\n","in_features = 8\n","out_features = 4\n","batch_size = 4\n","learning_rate = 1e-4\n","\n","# Create tensors for the loss\n","x = torch.zeros((batch_size, in_features))\n","y = torch.ones((batch_size, out_features))\n","\n","# Create the model to optimize\n","model = nn.Linear(in_features, out_features)\n","\n","# Instantiate an optimizer on the parameters of the Linear model.\n","optimizer = torch.optim.SGD(model.parameters(), learning_rate)\n","\n","# Instantiate the loss\n","l1_loss = nn.L1Loss()\n","\n","# 1. Perform computations\n","y_pred = model(x)\n","\n","# 2. Compute the loss term\n","loss = l1_loss(y_pred, y)\n","\n","# 3. Compute the gradients on the loss term all tensors involved in the computation now have a .grad value\n","loss.backward()\n","\n","# 4. Perform the optimization step with the gradient values in .grad\n","optimizer.step()\n","\n","# 5. Set all .grad attributes to 0 for the next optimization cycle\n","optimizer.zero_grad()\n","\n","print(\"> loss\")\n","print(loss)"]},{"cell_type":"markdown","metadata":{"id":"MI26r5hx9K7K"},"source":["## Datasets and Dataloaders\n","While we could manually load training data into input tensors, doing so would be a major performance bottleneck in training a deep model. For this reason, PyTorch provides a range of utilities in the `torch.utils.data` package that helps us efficiently deal with data. The most relevant ones are the `Dataset` and `DataLoader` classes.\n","\n","* the `Dataset` class represents our training data and contains the logic to load a single element. We typically subclass it when creating a new dataset.\n","* The `DataLoader` class is a utility class that efficiently loads a batch of data from a dataset. Multiprocessing speeds up data processing and overlaps the processing of the next batch with the current model computations.\n","\n","Subclassing the Dataset class requires overriding the `__len__` and the `__getitem__` methods to return respectively the number of elements in the dataset and the item at a specified position. Any object type can be returned by the `__getitem__` method.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PAOvcIHD9Hu8"},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset\n","\n","class SimpleDataset(Dataset):\n","    \"\"\"A simple dataset representing the numbers from 0 to size-1\"\"\"\n","\n","    def __init__(self, size):\n","        super(SimpleDataset, self).__init__()\n","\n","        self.size = size\n","\n","    def __getitem__(self, idx):\n","        \"\"\"Get an item given its id.\n","\n","        Args:\n","          idx: the integral index of the element to retrieve\n","\n","        Returns:\n","          element at index idx\n","        \"\"\"\n","        return torch.tensor([idx], dtype=torch.float32)\n","\n","    def __len__(self):\n","        \"\"\"Get the length of the dataset.\n","\n","        Returns:\n","          number of elements that compose the dataset\n","        \"\"\"\n","        return self.size\n","\n","size = 10\n","\n","# instantiate the dataset\n","dataset = SimpleDataset(size)\n","\n","# fetch the length of the dataset (__len__ method)\n","length = len(dataset)\n","print(f\"> Dataset length: {length}\")\n","\n","# get each element of the dataset through indexing\n","# (__getitem__ method)\n","for idx in range(len(dataset)):\n","  print(f\"- {idx}: {dataset[idx]}\")"]},{"cell_type":"markdown","metadata":{"id":"6DeUQXJK9oab"},"source":["A range of methods are provided to conveniently work with datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZIvCF0jZ9i5V"},"outputs":[],"source":["train_size = 6\n","val_size = 2\n","test_size = 2\n","\n","# split the dataset into training, validation and test sets\n","train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n","\n","# print all the splits\n","for current_dataset in [train_dataset, val_dataset, test_dataset]:\n","    current_length = len(current_dataset)\n","    print(f\"> Current length: {current_length}\")\n","    for idx in range(current_length):\n","        print(f\"- {idx}: {current_dataset[idx]}\")"]},{"cell_type":"markdown","metadata":{"id":"YRi07gnK9zcg"},"source":["Once a `Dataset` instance is available, a `DataLoader` object can be used to efficiently gather batches of data from the dataset. We just need to specify the size of the batch we would like to retrieve, the number of parallel workers to use for data processing, and whether or not we would like batch elements to be sampled randomly from the dataset.\n","\n","The DataLoader object is iterable and yields a batch of data at each iteration. Internally, when a batch is requested, the dataloader uses the `Dataset` `__getitem__` method to retrieve each item in the batch. If the object type returned by this function is known to PyTorch (eg. it is a Tensor), then they are automatically combined into a single object representing the batch. For example, if the returned type is Tensor, PyTorch fuses all Tensors composing the batch into a single Tensor with an additional initial dimension of size equal to the batch size. If the dataset returns custom data types instead, a `collate_fn` function can be manually specified that takes as input a list of objects returned by the dataset and returns a single object representing the entire batch.\n","\n","Due to `DataLoader parallelism, PyTorch recommends that objects returned by datasets be placed in CPU memory due to the subtleties in handling objects placed in GPU memory from multiple processes."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0NvsNpBX9sCb"},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","# Creates a dataloader for our dataset instance.\n","# Does not randomize the order of elements and returns the last batch even if\n","# it is not of size batch_size\n","dataloader = DataLoader(dataset, num_workers=2, batch_size=4, shuffle=False, drop_last=False)\n","\n","print(f\"> Length of dataset: {len(dataset)}\")\n","\n","print(\"> Unshuffled DataLoader\")\n","for idx, batch in enumerate(dataloader):\n","  print(f\"Batch {idx}:\")\n","  print(batch)"]},{"cell_type":"markdown","metadata":{"id":"rLvW5P2q-J4T"},"source":["## Transformations\n","\n","The `Dataset` class gives us the freedom to insert data augmentation strategies directly inside the `__getitem__` method implementation. Doing so, however, is inconvenient since for the same dataset we may want to apply different augmentation, for example during training and during evaluation.\n","\n","For this reason, a typical pattern in PyTorch is providing to the Dataset constructor a `transform` function. The Dataset class, will apply the desired transformations **before** returning the `__getitem__` value, thus actually returning `transform(__getitem__(idx))`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GDXgBEDD-Dni"},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset\n","\n","\n","class TransformableDataset(Dataset):\n","    \"\"\"A simple dataset class representing the numbers from 0 to size - 1\"\"\"\n","    def __init__(self, size, transform=None):\n","        super(TransformableDataset, self).__init__()\n","\n","        self.transform = transform\n","        self.size = size\n","\n","    def __getitem__(self, idx):\n","        \"\"\"Get an item given its id.\n","\n","        Args:\n","          idx: the integral index of the element to retrieve\n","\n","        Returns:\n","          element at index idx\n","        \"\"\"\n","        result = torch.tensor([idx], dtype=torch.float32)\n","\n","        # If a transformation is available, we apply it\n","        if self.transform is not None:\n","          result = self.transform(result)\n","\n","        return result\n","\n","    def __len__(self):\n","        \"\"\"Get the length of the dataset.\n","\n","        Returns:\n","          number of elements that compose the dataset\n","        \"\"\"\n","        return self.size\n","\n","# A simple transformation\n","def square(input):\n","  return input ** 2\n","\n","size = 10\n","\n","# Instantiates the dataset\n","dataset = TransformableDataset(size, transform=square)\n","\n","# Gets the length of the dataset (__len__ method)\n","length = len(dataset)\n","print(f\"> Dataset length: {length}\")\n","\n","# Gets each element of the dataset through indexing\n","# (__getitem__ method)\n","for idx in range(len(dataset)):\n","  print(f\"- {idx}: {dataset[idx]}\")"]},{"cell_type":"markdown","metadata":{"id":"ezJqpWrb-t9M"},"source":["Many transformations are available in PyTorch. In particular, the `torchvision.transforms` package contains a range of transformations designed for images and utilities to compose a complex chain of transformations into a single pipeline.\n","\n","When designing a transformation, it is important to consider that PyTorch datasets typically return images represented by the PIL Image class, which is the format expected by many of the transformations in the `torchvision.transforms` package. The `ToTensor` transformation can be used to convert PIL Images to Tensors."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cLfaDzTx-e9G"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import torch\n","import torchvision\n","from torchvision import transforms\n","\n","# Obtains the CIFAR100 dataset, downloading it if necessary\n","# Each returned element is a tuple (PIL Image, int) with the int representing the label of the image\n","# transform is applied only to the first element in the tuple\n","# target_transform can be specified for the second element\n","dataset = torchvision.datasets.CIFAR100(root=\"cifar100\", transform=None, download=True)\n","\n","# Plots the first 10 images without transformations\n","fig, axs = plt.subplots(3, 3, figsize=(5, 5))\n","for ax_idx, ax in enumerate(axs.flatten()):\n","    sample_image, sample_label = dataset[ax_idx]\n","\n","    ax.axis(\"off\")\n","    ax.set_title(f\"Class: {sample_label}\")\n","    ax.imshow(np.asarray(sample_image))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"73xcWGHS_D3t"},"outputs":[],"source":["from torchvision import transforms\n","\n","# Build a transformation that will apply a random affine transformation\n","affine_transformation = transforms.RandomAffine(degrees=20, translate=(0.1, 0.1))\n","\n","# Pass transformation to dataset\n","dataset = torchvision.datasets.CIFAR100(root=\"cifar100\", transform=affine_transformation, download=True)\n","\n","# Plots the first 10 images\n","fig, axs = plt.subplots(3, 3, figsize=(5, 5))\n","for ax_idx, ax in enumerate(axs.flatten()):\n","    sample_image, sample_label = dataset[ax_idx]\n","\n","    ax.axis(\"off\")\n","    ax.set_title(f\"Class: {sample_label}\")\n","    ax.imshow(np.asarray(sample_image))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t6RYqSm5XkWj"},"outputs":[],"source":["from torchvision import transforms\n","\n","# We can also build a chain of transformations\n","transformations_sequence = [\n","  transforms.RandomAffine(degrees=20, translate=(0.1, 0.1)),\n","  # Random changes in pixel colors\n","  transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n","  # The former transformations accept and return PIL Image objects, now convert to Tensor\n","  transforms.ToTensor(),\n","  # Apply normalization\n","  transforms.Normalize(mean=[0.4913, 0.4821, 0.4465], std=[0.2470, 0.2434, 0.2615])\n","]\n","composed_transformation = transforms.Compose(transformations_sequence)\n","\n","# Pass transformation to dataset\n","dataset = torchvision.datasets.CIFAR100(root=\"cifar100\", transform=composed_transformation, download=True)\n","\n","# Plots the first 10 images\n","fig, axs = plt.subplots(3, 3, figsize=(5, 5))\n","for ax_idx, ax in enumerate(axs.flatten()):\n","    sample_image, sample_label = dataset[ax_idx]\n","\n","    ax.axis(\"off\")\n","    ax.set_title(f\"Class: {sample_label}\")\n","    # Because the sample_image is a Tensor of shape [channels, height, width], we need to reshape it so that matplotlib can show it\n","    # [channels, height, width] => [height, width, channels]\n","    ax.imshow(sample_image.permute(1, 2, 0))"]},{"cell_type":"markdown","metadata":{"id":"Szh0JdG5_Yms"},"source":["## Logging\n","\n","Understanding the training behavior of deep models is often challenging. However, a wide variety of metrics can give us clues on why a certain behavior is shown. Moreover, when working on a deep learning project, multiple configurations and architecture variations are typically tested, generating a large quantity of data. Thus, being able to explore these data and compare them among different configurations is of primary importance.\n","\n","Multiple tools are available to achieve this goal. We will quickly cover two main logging utilities: Tensorboard and WandB. The idea behind these tools is simple: when training or evaluating a model, we log some metrics at each step, and the tool provides us with a web interface where plots showing the dynamics of our model are automatically populated."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fabG4yHy_Qkm"},"outputs":[],"source":["# Let's clear previous runs (if any)\n","!rm -r runs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PdessMPm_k99"},"outputs":[],"source":["import torch\n","from torch.utils.tensorboard import SummaryWriter\n","\n","# ====== Write fake data representing a first experiment ====== #\n","# Creates a logger for the experiment\n","writer = SummaryWriter(log_dir=\"runs/exp1\")\n","\n","# Simulate 100 training steps\n","for training_step in range(100):\n","    # Log training metrics\n","    writer.add_scalar(\"train/quantity_a\", training_step * 0.5, training_step)\n","    writer.add_scalar(\"train/quantity_b\", training_step ** 1.5, training_step)\n","    writer.add_scalar(\"train/quantity_c\", 1 / (1 + training_step), training_step)\n","\n","# Close the logger\n","writer.close()\n","\n","# ====== Write fake data representing a second experiment ====== #\n","writer = SummaryWriter(log_dir=\"runs/exp2\")\n","\n","for training_step in range(100):\n","    writer.add_scalar(\"train/quantity_a\", training_step * 0.4, training_step)\n","    writer.add_scalar(\"train/quantity_b\", training_step ** 1.4, training_step)\n","    writer.add_scalar(\"train/quantity_c\", 1 / (1 + 2 * training_step), training_step)\n","\n","writer.close()\n","# ============================================================== #"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X-oPypMK_m-i"},"outputs":[],"source":["# If you are getting an error, enable third-party cookies!\n","%load_ext tensorboard\n","%tensorboard --logdir=runs"]},{"cell_type":"markdown","metadata":{"id":"jU8ZlizCAkTc"},"source":["Let's now try out WandB"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0YdDgGRGAoDn","collapsed":true},"outputs":[],"source":["# Import the library\n","import wandb\n","\n","wandb.login()\n","\n","# ====== Write fake data representing a first experiment ====== #\n","wandb.init(project=\"lab_01_intro\", name=\"exp1\")\n","\n","# Simulate 100 training steps\n","for training_step in range(100):\n","    # Log training metrics\n","    wandb.log({\n","        \"train/quantity_a\": training_step * 0.5,\n","        \"train/quantity_b\": training_step ** 1.5,\n","        \"train/quantity_c\": 1 / (1 + training_step),\n","    })\n","\n","# ====== Write fake data representing a second experiment ====== #\n","wandb.init(project=\"lab_01_intro\", name=\"exp2\")\n","\n","for training_step in range(100):\n","    # Log training metrics\n","    wandb.log({\n","        \"train/quantity_a\": training_step * 0.4,\n","        \"train/quantity_b\": training_step ** 1.3,\n","        \"train/quantity_c\": 1 / (1 + 2 *training_step),\n","    })"]}],"metadata":{"colab":{"provenance":[{"file_id":"19HM8ViNaJQOHGGwKRLd9jIB0jj_G9g4J","timestamp":1679661240714},{"file_id":"1OwecYKSzAAOJqop3WC4bO_gKyZzDBdbJ","timestamp":1646063874364}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}